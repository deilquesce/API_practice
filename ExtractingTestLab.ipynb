{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deilquesce/API_practice/blob/main/ExtractingTestLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnXzcZvdc-r6"
      },
      "source": [
        "In this notebook we will demostrate how to perform tokenization,stemming,lemmatization and pos_tagging using libraries like [spacy](https://spacy.io/) and [nltk](https://www.nltk.org/) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3xEmJpRc5r8"
      },
      "outputs": [],
      "source": [
        "#This will be our corpus which we will work on\n",
        "corpus_original = \"Need to finalize the demo corpus which will be used for this notebook and it should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n",
        "corpus = \"I love to work on cars in my possession. It makes me very passionate and fufilled! 2 \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHh_33IopPTf",
        "outputId": "8c25466b-bfa1-41dc-b9e7-97bd77d3e6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love to work on cars in my possession. it makes me very passionate and fufilled! 2 \n"
          ]
        }
      ],
      "source": [
        "#lower case the corpus\n",
        "corpus = corpus.lower()\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yaGf8RiqgBM",
        "outputId": "b1c19c07-806a-4f3d-f151-126578757244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love to work on cars in my possession. it makes me very passionate and fufilled!  \n"
          ]
        }
      ],
      "source": [
        "#removing digits in the corpus\n",
        "import re\n",
        "corpus = re.sub(r'\\d+','', corpus)\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Q--GItqzfu",
        "outputId": "7b3cc44b-12d5-4aa2-e444-721119e784f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love to work on cars in my possession it makes me very passionate and fufilled  \n"
          ]
        }
      ],
      "source": [
        "#removing punctuations\n",
        "import string\n",
        "corpus = corpus.translate(str.maketrans('', '', string.punctuation))\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zmANqee9rK4N",
        "outputId": "6c8d9d3c-cfc7-4d79-9aa5-2a4a862d9185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i love to work on cars in my possession it makes me very passionate and fufilled'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#removing trailing whitespaces\n",
        "corpus = ' '.join([token for token in corpus.split()])\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMuHZTpy9X_u",
        "outputId": "88b10c4d-27e7-49cc-fe02-7ae42edd56be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==3.0.5 in /usr/local/lib/python3.8/dist-packages (3.0.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (2.11.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (3.0.11)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (4.64.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (0.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (57.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (3.0.8)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (1.7.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (0.7.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.0.5) (8.0.17)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy==3.0.5) (3.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy==3.0.5) (6.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.5) (4.0.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.5) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy==3.0.5) (2.0.1)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.21.6)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.17)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.11)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (6.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2022.12.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy==3.0.5\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfJx3MnVj_ph"
      },
      "source": [
        "### Tokenizing the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUz580k2sMqf",
        "outputId": "c78bd55a-3706-4db3-c41d-89590be029cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLTK\n",
            "Tokenized corpus: ['i', 'love', 'to', 'work', 'on', 'cars', 'in', 'my', 'possession', 'it', 'makes', 'me', 'very', 'passionate', 'and', 'fufilled']\n",
            "Tokenized corpus without stopwords: ['love', 'work', 'cars', 'possession', 'makes', 'passionate', 'fufilled']\n",
            "\n",
            "Spacy:\n",
            "Tokenized Corpus: ['i', 'love', 'to', 'work', 'on', 'cars', 'in', 'my', 'possession', 'it', 'makes', 'me', 'very', 'passionate', 'and', 'fufilled']\n",
            "Tokenized corpus without stopwords ['love', 'work', 'cars', 'possession', 'makes', 'passionate', 'fufilled']\n",
            "Difference between NLTK and spaCy output:\n",
            " set()\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "##NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words_nltk = set(stopwords.words('english'))\n",
        "\n",
        "tokenized_corpus_nltk = word_tokenize(corpus)\n",
        "print(\"\\nNLTK\\nTokenized corpus:\",tokenized_corpus_nltk)\n",
        "tokenized_corpus_without_stopwords = [i for i in tokenized_corpus_nltk if not i in stop_words_nltk]\n",
        "print(\"Tokenized corpus without stopwords:\",tokenized_corpus_without_stopwords)\n",
        "\n",
        "\n",
        "##SPACY \n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "stopwords_spacy = spacy_model.Defaults.stop_words\n",
        "print(\"\\nSpacy:\")\n",
        "tokenized_corpus_spacy = word_tokenize(corpus)\n",
        "print(\"Tokenized Corpus:\",tokenized_corpus_spacy)\n",
        "tokens_without_sw= [word for word in tokenized_corpus_spacy if not word in stopwords_spacy]\n",
        "\n",
        "print(\"Tokenized corpus without stopwords\",tokens_without_sw)\n",
        "\n",
        "\n",
        "print(\"Difference between NLTK and spaCy output:\\n\",\n",
        "      set(tokenized_corpus_without_stopwords)-set(tokens_without_sw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRH_ltkD-HpA"
      },
      "source": [
        "Notice the difference output after stopword removal using nltk and spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGcwD1JlkEao"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibEpzcv0sdW8",
        "outputId": "dfc394ee-555f-4e72-c9a8-508346b81758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Stemming:\n",
            "i love to work on cars in my possession it makes me very passionate and fufilled\n",
            "After Stemming:\n",
            "i love to work on car in my possess it make me veri passion and fufil "
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer= PorterStemmer()\n",
        "\n",
        "print(\"Before Stemming:\")\n",
        "print(corpus)\n",
        "\n",
        "print(\"After Stemming:\")\n",
        "for word in tokenized_corpus_nltk:\n",
        "    print(stemmer.stem(word),end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wy6cwvYkJeR"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27KvL4ZE-fqJ",
        "outputId": "31e7082e-3736-4ae6-d086-1ac18073c937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i love to work on car in my possession it make me very passionate and fufilled "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "  \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "for word in tokenized_corpus_nltk:\n",
        "    print(lemmatizer.lemmatize(word),end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8uCGA8ukMfQ"
      },
      "source": [
        "### POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZqBxLDz-6cu",
        "outputId": "4480c501-3e1c-4518-ccc7-2a9715349fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging using spacy:\n",
            "I : PRON\n",
            "love : VERB\n",
            "to : PART\n",
            "work : VERB\n",
            "on : ADP\n",
            "cars : NOUN\n",
            "in : ADP\n",
            "my : PRON\n",
            "possession : NOUN\n",
            ". : PUNCT\n",
            "It : PRON\n",
            "makes : VERB\n",
            "me : PRON\n",
            "very : ADV\n",
            "passionate : ADJ\n",
            "and : CCONJ\n",
            "fufilled : VERB\n",
            "! : PUNCT\n",
            "2 : NUM\n",
            "POS Tagging using NLTK:\n",
            "[('I', 'PRP'),\n",
            " ('love', 'VBP'),\n",
            " ('to', 'TO'),\n",
            " ('work', 'VB'),\n",
            " ('on', 'IN'),\n",
            " ('cars', 'NNS'),\n",
            " ('in', 'IN'),\n",
            " ('my', 'PRP$'),\n",
            " ('possession', 'NN'),\n",
            " ('.', '.'),\n",
            " ('It', 'PRP'),\n",
            " ('makes', 'VBZ'),\n",
            " ('me', 'PRP'),\n",
            " ('very', 'RB'),\n",
            " ('passionate', 'JJ'),\n",
            " ('and', 'CC'),\n",
            " ('fufilled', 'VBD'),\n",
            " ('!', '.'),\n",
            " ('2', 'CD')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "#POS tagging using spacy\n",
        "corpus_original = \"I love to work on cars in my possession. It makes me very passionate and fufilled! 2\"\n",
        "print(\"POS Tagging using spacy:\")\n",
        "doc = spacy_model(corpus_original)\n",
        "# Token and Tag\n",
        "for token in doc:\n",
        "    print(token,\":\", token.pos_)\n",
        "\n",
        "#pos tagging using nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "print(\"POS Tagging using NLTK:\")\n",
        "pprint(nltk.pos_tag(word_tokenize(corpus_original)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWdmz6lFkpEI"
      },
      "source": [
        "There are various other libraries you can use to perform these common pre-processing steps"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}